#!/usr/bin/env python3
"""
text_and_symbol_batch.py
• Multi-scale EAST  → text  (red)
• Tile-based YOLOv8 → symbols (blue)   — loads your custom best.pt

usage:
  python3 text_and_symbol_batch.py INPUT_DIR  OUTPUT_DIR
  # optional overrides
  python3 text_and_symbol_batch.py \
      --weights runs/detect/symbol_30shot/weights/best.pt \
      --east_conf 0.08 --yolo_conf 0.08 \
      INPUT_DIR  OUTPUT_DIR
"""

import os, sys, cv2, argparse, numpy as np
from pathlib import Path
from typing import List, Tuple
from PIL import Image
import torch
from ultralytics import YOLO
from imutils.object_detection import non_max_suppression

# ────────── early --weights flag ──────────
early = argparse.ArgumentParser(add_help=False)
early.add_argument(
    "--weights", default="weights/icon_detect/best.pt",
    help="Path to custom symbol model (.pt)")
_e, _ = early.parse_known_args()
SYMBOL_WEIGHTS = _e.weights

if not torch.cuda.is_available():
    sys.exit("❌  No CUDA GPU detected.")
if not Path(SYMBOL_WEIGHTS).is_file():
    sys.exit(f"❌  Weights '{SYMBOL_WEIGHTS}' not found")

# ---- load YOLO symbol detector once ----
sym_model = YOLO(SYMBOL_WEIGHTS).to("cuda")
try: sym_model.model.half()
except AttributeError: pass

# ────────── EAST detector class ──────────
class MultiResolutionEAST:
    def __init__(self, pb_path, resolutions):
        self.net = cv2.dnn.readNet(pb_path)
        self.res = resolutions
        self.layers = ["feature_fusion/Conv_7/Sigmoid",
                       "feature_fusion/concat_3"]

    def _detect_at(self, img, target, conf):
        H,W = img.shape[:2]; newW,newH = target
        rW,rH = W/newW, H/newH
        blob = cv2.dnn.blobFromImage(cv2.resize(img,target),
                                     1.0,target,(123.68,116.78,103.94),
                                     swapRB=True, crop=False)
        self.net.setInput(blob)
        scores, geo = self.net.forward(self.layers)
        boxes, scores_out = [], []
        for y in range(scores.shape[2]):
            sd = scores[0,0,y]
            x0,x1,x2,x3,ang = geo[0,0,y],geo[0,1,y],geo[0,2,y],geo[0,3,y],geo[0,4,y]
            for x in range(scores.shape[3]):
                if sd[x] < conf: continue
                offX,offY = x*4.0, y*4.0
                cos,sin = np.cos(ang[x]), np.sin(ang[x])
                h,w = x0[x]+x2[x], x1[x]+x3[x]
                endX = int(offX+cos*x1[x]+sin*x2[x])
                endY = int(offY-sin*x1[x]+cos*x2[x])
                startX, startY = int(endX-w), int(endY-h)
                boxes.append((int(startX*rW),int(startY*rH),
                              int(endX*rW),  int(endY*rH)))
                scores_out.append(float(sd[x]))
        return non_max_suppression(np.array(boxes), probs=scores_out).tolist() if boxes else []

    def detect(self, img, conf=0.5):
        allb=[self._detect_at(img,r,conf) for r in self.res]
        flat=[b for sub in allb for b in sub]
        return non_max_suppression(np.array(flat),overlapThresh=0.7).tolist() if flat else []

east = MultiResolutionEAST("frozen_east_text_detection.pb",
                           [(960,960),(1600,1600),(3776,3776)])

# ────────── helper functions ──────────
def gen_tiles(img, size, ov):
    h,w = img.shape[:2]; step=max(size-ov,1)
    for y in range(0,h,step):
        for x in range(0,w,step):
            yield img[y:y+size,x:x+size],x,y

def detect_symbols(img,size,ov,conf,iou_thr):
    boxes=[]
    for tile,ox,oy in gen_tiles(img,size,ov):
        r=sym_model.predict(tile,device="cuda",conf=conf,
                            iou=iou_thr,half=True,verbose=False)
        if r and len(r[0].boxes):
            for b in r[0].boxes:
                x1,y1,x2,y2=map(int,b.xyxy[0].tolist())
                boxes.append((x1+ox,y1+oy,x2+ox,y2+oy))
    return boxes

def iou(a,b):
    xA,yA=max(a[0],b[0]),max(a[1],b[1])
    xB,yB=min(a[2],b[2]),min(a[3],b[3])
    if xB<xA or yB<yA:return 0
    inter=(xB-xA)*(yB-yA)
    return inter/((a[2]-a[0])*(a[3]-a[1])+(b[2]-b[0])*(b[3]-b[1])-inter+1e-9)

def merge(lst,thr):
    if not lst:return []
    lst=sorted(lst,key=lambda b:(b[2]-b[0])*(b[3]-b[1]),reverse=True)
    used=[False]*len(lst);out=[]
    for i,b in enumerate(lst):
        if used[i]:continue
        cur=b
        for j in range(i+1,len(lst)):
            if used[j]:continue
            if iou(cur,lst[j])>thr:
                cur=(min(cur[0],lst[j][0]),min(cur[1],lst[j][1]),
                     max(cur[2],lst[j][2]),max(cur[3],lst[j][3]))
                used[j]=True
        used[i]=True; out.append(cur)
    return out

def draw(img,boxes,col,th=2):
    out=img.copy()
    for x1,y1,x2,y2 in boxes:
        cv2.rectangle(out,(x1,y1),(x2,y2),col,th)
    return out

# ────────── CLI full parser ──────────
p=argparse.ArgumentParser(parents=[early],
    description="Detect text (EAST) + symbols (YOLO) & save annotated images")
p.add_argument("input_dir"); p.add_argument("output_dir")
p.add_argument("--tile",type=int,default=1024)
p.add_argument("--overlap",type=int,default=128)
p.add_argument("--east_conf",type=float,default=0.5)
p.add_argument("--yolo_conf",type=float,default=0.25)
p.add_argument("--merge_iou", type=float, default=0.3)
args=p.parse_args()

# ────────── main loop ──────────
Path(args.output_dir).mkdir(parents=True,exist_ok=True)
exts=(".png",".jpg",".jpeg",".bmp",".tif",".tiff")

for fn in sorted(os.listdir(args.input_dir)):
    if not fn.lower().endswith(exts):continue
    img=cv2.cvtColor(np.array(Image.open(Path(args.input_dir)/fn).convert("RGB")),
                     cv2.COLOR_RGB2BGR)
    print("→",fn)
    txt=east.detect(img,conf=args.east_conf)
    sym=detect_symbols(img,args.tile,args.overlap,args.yolo_conf,0.45)
    sym=merge(sym,args.merge_iou)
    print(f"   text:{len(txt)}  symbol:{len(sym)}")

    anno=draw(img,txt,(0,0,255),2)
    anno=draw(anno,sym,(255,0,0),2)
    cv2.imwrite(str(Path(args.output_dir)/f"{Path(fn).stem}_annotated.png"),anno)

print("✅ results →", args.output_dir)

