#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
full_ocr_symbol_pipeline.py
───────────────────────────
Red  = text (EAST + PaddleOCR + EasyOCR)
Blue = symbols (custom YOLOv8)   [class label above box]

Run
───
python3 full_ocr_symbol_pipeline.py \
        --east_conf 0.05 --yolo_conf 0.05 \
        "OCR TEST-28-04-25"  OUTPUT_DIR
"""

import os, sys, cv2, argparse, numpy as np
from pathlib import Path
from typing import List, Tuple
from PIL import Image
import torch
from ultralytics import YOLO
from paddleocr import PaddleOCR
import easyocr
from imutils.object_detection import non_max_suppression

# ───────────── 0. GPU + model paths ─────────────
if not torch.cuda.is_available():
    sys.exit("❌  CUDA GPU not available.")

CLI = argparse.ArgumentParser(add_help=False)
CLI.add_argument("--weights", default="weights/icon_detect/best.pt",
                 help="YOLO symbol model (.pt)")
ARGS0, _ = CLI.parse_known_args()

YOLO_WEIGHTS = Path(ARGS0.weights)
if not YOLO_WEIGHTS.is_file():
    sys.exit(f"❌  YOLO weights '{YOLO_WEIGHTS}' not found.")

# ───────────── 0.a  Load models ONCE ─────────────
sym_model = YOLO(str(YOLO_WEIGHTS)).to("cuda")
try: sym_model.model.half()
except AttributeError: pass

paddle_det = PaddleOCR(det=True, rec=False, use_angle_cls=False,
                       lang="en", show_log=False, use_gpu=True)
easy_reader = easyocr.Reader(["en"], gpu=True)

# ───────────── 1. Multi-Resolution EAST ─────────────
class MultiResEAST:
    def __init__(self, pb, resolutions):
        self.net = cv2.dnn.readNet(pb)
        self.res = resolutions
        self.layers = ["feature_fusion/Conv_7/Sigmoid",
                       "feature_fusion/concat_3"]
    def _pass(self, img, tgt, conf):
        H,W = img.shape[:2]; newW,newH = tgt
        rW,rH = W/newW, H/newH
        blob = cv2.dnn.blobFromImage(cv2.resize(img,tgt),1.0,tgt,
                                     (123.68,116.78,103.94),
                                     swapRB=True,crop=False)
        self.net.setInput(blob)
        scores,geo = self.net.forward(self.layers)
        boxes,sc = [],[]
        for y in range(scores.shape[2]):
            sd = scores[0,0,y]
            x0,x1,x2,x3,ang = geo[0,0,y],geo[0,1,y],geo[0,2,y],geo[0,3,y],geo[0,4,y]
            for x in range(scores.shape[3]):
                if sd[x] < conf: continue
                oX,oY = x*4., y*4.
                cos,sin = np.cos(ang[x]), np.sin(ang[x])
                h,w = x0[x]+x2[x], x1[x]+x3[x]
                eX = int(oX + cos*x1[x] + sin*x2[x])
                eY = int(oY - sin*x1[x] + cos*x2[x])
                sX,sY = int(eX-w), int(eY-h)
                boxes.append((int(sX*rW), int(sY*rH),
                              int(eX*rW), int(eY*rH)))
                sc.append(float(sd[x]))
        return non_max_suppression(np.array(boxes), probs=sc).tolist() if boxes else []
    def detect(self, img, conf=0.5):
        coll = [self._pass(img,r,conf) for r in self.res]
        flat = [b for sub in coll for b in sub]
        return non_max_suppression(np.array(flat), overlapThresh=0.7).tolist() if flat else []

east = MultiResEAST("frozen_east_text_detection.pb",
                    [(960,960),(1600,1600),(3776,3776),(8192,8192)])

# ───────────── 2. Tile helpers ─────────────
def tiles(img, size, ov):
    h,w = img.shape[:2]; step=max(size-ov,1)
    for y in range(0,h,step):
        for x in range(0,w,step):
            yield img[y:y+size, x:x+size], x, y

# ───────────── 3. YOLO symbols (bbox + cls) ─────────────
def detect_symbols(img, sz, ov, conf, iou):
    out=[]
    for tile,ox,oy in tiles(img,sz,ov):
        r=sym_model.predict(tile,device="cuda",conf=conf,iou=iou,
                            half=True,verbose=False)
        if r and len(r[0].boxes):
            names = sym_model.names
            for b in r[0].boxes:
                x1,y1,x2,y2 = map(int,b.xyxy[0].tolist())
                cls = int(b.cls[0])
                out.append((x1+ox,y1+oy,x2+ox,y2+oy,cls))
    return out

# ───────────── 4. IoU merge (keep first cls) ─────────────
def iou(a,b):
    xA,yA = max(a[0],b[0]), max(a[1],b[1])
    xB,yB = min(a[2],b[2]), min(a[3],b[3])
    if xB<xA or yB<yA: return 0
    inter=(xB-xA)*(yB-yA)
    return inter/(((a[2]-a[0])*(a[3]-a[1])+(b[2]-b[0])*(b[3]-b[1])-inter)+1e-9)
def merge_sym(boxes, thr):
    if not boxes: return []
    boxes = sorted(boxes, key=lambda b:(b[2]-b[0])*(b[3]-b[1]), reverse=True)
    used=[False]*len(boxes); out=[]
    for i,b in enumerate(boxes):
        if used[i]: continue
        cur=b
        for j in range(i+1,len(boxes)):
            if used[j]: continue
            if iou(cur,boxes[j])>thr:
                cur=(min(cur[0],boxes[j][0]),min(cur[1],boxes[j][1]),
                     max(cur[2],boxes[j][2]),max(cur[3],boxes[j][3]),cur[4])
                used[j]=True
        used[i]=True; out.append(cur)
    return out

# ───────────── 5. Mask helpers ─────────────
def mask(img, boxes):
    m = img.copy()
    for x1,y1,x2,y2 in boxes:
        cv2.rectangle(m,(x1,y1),(x2,y2),(0,0,0),-1)
    return m

# ───────────── 6. OCR detectors ─────────────
def detect_paddle(img, sz, ov, box_thr=0.3):
    out=[]
    for tile,ox,oy in tiles(img,sz,ov):
        res = paddle_det.ocr(tile, cls=False)
        for page in res:
            for line in page:
                pts,_ = line
                xs=[p[0] for p in pts]; ys=[p[1] for p in pts]
                out.append((int(min(xs)+ox),int(min(ys)+oy),
                            int(max(xs)+ox),int(max(ys)+oy)))
    return out

def detect_easy(img, sz, ov):
    out=[]
    for tile,ox,oy in tiles(img,sz,ov):
        res = easy_reader.readtext(cv2.cvtColor(tile,cv2.COLOR_BGR2RGB),
                                   detail=1) or []
        for box,text,conf in res:
            xs=[p[0] for p in box]; ys=[p[1] for p in box]
            out.append((int(min(xs)+ox),int(min(ys)+oy),
                        int(max(xs)+ox),int(max(ys)+oy)))
    return out

# ───────────── 7. Cleanup (large containing boxes) ─────────────
def is_contained(small,big):
    return small[0]>=big[0] and small[1]>=big[1] and \
           small[2]<=big[2] and small[3]<=big[3]
def cleanup(boxes, thr=0.8):
    if not boxes: return []
    area=lambda b:(b[2]-b[0])*(b[3]-b[1])
    boxes=sorted(boxes,key=area,reverse=True)
    keep=[True]*len(boxes)
    for i,big in enumerate(boxes):
        if not keep[i]: continue
        big_a=area(big); covered=0; cnt=0
        for j,sm in enumerate(boxes[i+1:], start=i+1):
            if not keep[j]: continue
            if is_contained(sm,big):
                covered+=area(sm); cnt+=1
        if cnt>1 and covered/big_a>=thr:
            keep[i]=False
    return [b for k,b in zip(keep,boxes) if k]

# ───────────── 8. Draw ─────────────
def draw_text(img, boxes):
    return draw(img, boxes, (0,0,255), 2)

def draw_symbols(img, boxes, names):
    out=img.copy()
    for x1,y1,x2,y2,cls in boxes:
        cv2.rectangle(out,(x1,y1),(x2,y2),(255,0,0),2)
        label = names.get(cls,str(cls))
        cv2.putText(out, label, (x1, y1-5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1, cv2.LINE_AA)
    return out

# ───────────── 9. Main CLI ─────────────
def main():
    p=argparse.ArgumentParser(parents=[CLI],
        description="Full OCR + Symbol pipeline (red=text, blue=symbol)")
    p.add_argument("input_dir"); p.add_argument("output_dir")
    p.add_argument("--tile",type=int,default=1024)
    p.add_argument("--overlap",type=int,default=128)
    p.add_argument("--east_conf",type=float,default=0.5)
    p.add_argument("--yolo_conf",type=float,default=0.25)
    p.add_argument("--merge_iou",type=float,default=0.3)
    args=p.parse_args()

    Path(args.output_dir).mkdir(parents=True,exist_ok=True)
    exts=(".png",".jpg",".jpeg",".bmp",".tif",".tiff")

    for fn in sorted(os.listdir(args.input_dir)):
        if not fn.lower().endswith(exts): continue
        img=cv2.cvtColor(np.array(
            Image.open(Path(args.input_dir)/fn).convert("RGB")),
            cv2.COLOR_RGB2BGR)

        # Step 1: EAST
        east_boxes = east.detect(img, conf=args.east_conf)

        # Step 2: YOLO symbols
        sym_raw = detect_symbols(img,args.tile,args.overlap,
                                 args.yolo_conf,0.45)
        sym_boxes = merge_sym(sym_raw,args.merge_iou)

        # Step 3: Combine EAST+YOLO and mask for Paddle
        combined = east_boxes + [b[:4] for b in sym_boxes]
        masked_east = mask(img, east_boxes)

        # Step 4: PaddleOCR on masked img
        paddle_boxes = detect_paddle(masked_east,args.tile,args.overlap)

        # Step 5: mask out Paddle → EasyOCR
        masked_paddle = mask(masked_east,paddle_boxes)
        easy_boxes = detect_easy(masked_paddle,args.tile,args.overlap)

        # Step 6: merge + cleanup
        all_txt = east_boxes + paddle_boxes + easy_boxes
        merged_txt = non_max_suppression(np.array(all_txt),
                                         overlapThresh=0.3).tolist() if all_txt else []
        final_txt = cleanup(merged_txt,thr=0.8)

        # Draw
        out = draw_text(img, final_txt)
        out = draw_symbols(out, sym_boxes, sym_model.names)

        cv2.imwrite(str(Path(args.output_dir)/f"{Path(fn).stem}_final.png"),out)
        print(f"{fn:25}  text:{len(final_txt):2d}  symbols:{len(sym_boxes):2d}")

    print("✅  Done →", args.output_dir)

if __name__ == "__main__":
    main()

