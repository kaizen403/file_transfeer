#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
text_symbol_batch.py
────────────────────
Detects:
  • TEXT    : multi-scale EAST  → red boxes
  • SYMBOLS : custom YOLOv8     → blue boxes

Example
───────
python3 text_symbol_batch.py \
        --east_conf 0.08 --yolo_conf 0.08 \
        "OCR TEST-28-04-25"  OCR_ANNOTATED

To use a different symbol model:
python3 text_symbol_batch.py \
        --weights runs/detect/symbol_model/weights/best.pt \
        INPUT_DIR  OUTPUT_DIR
"""
import os, sys, cv2, argparse, numpy as np
from pathlib import Path
from typing import List, Tuple
from PIL import Image
import torch
from ultralytics import YOLO
from imutils.object_detection import non_max_suppression

# ───────── 0. GPU + model loading ─────────
if not torch.cuda.is_available():
    sys.exit("❌  CUDA GPU not found.")

cli = argparse.ArgumentParser(add_help=False)
cli.add_argument("--weights", default="weights/icon_detect/best.pt",
                 help="YOLOv8 symbol model (.pt)")
args_first, _ = cli.parse_known_args()
SYMBOL_WEIGHTS = Path(args_first.weights)
if not SYMBOL_WEIGHTS.is_file():
    sys.exit(f"❌  Symbol weights '{SYMBOL_WEIGHTS}' not found.")

symbol_model = YOLO(str(SYMBOL_WEIGHTS)).to("cuda")
try:
    symbol_model.model.half()           # FP16 if GPU supports it
except AttributeError:
    pass

# ───────── 1. Multi-resolution EAST text detector ─────────
class MultiResolutionEAST:
    def __init__(self, pb_path: str, resolutions):
        self.net = cv2.dnn.readNet(pb_path)
        self.resolutions = resolutions
        self.layers = ["feature_fusion/Conv_7/Sigmoid",
                       "feature_fusion/concat_3"]

    def _detect(self, img, target, conf):
        H, W = img.shape[:2]; newW, newH = target
        rW, rH = W / newW, H / newH
        blob = cv2.dnn.blobFromImage(
            cv2.resize(img, target), 1.0, target,
            (123.68, 116.78, 103.94), swapRB=True, crop=False)
        self.net.setInput(blob)
        scores, geo = self.net.forward(self.layers)

        boxes, scores_out = [], []
        for y in range(scores.shape[2]):
            sd = scores[0, 0, y]
            x0, x1, x2, x3, ang = geo[0, 0, y], geo[0, 1, y], geo[0, 2, y], geo[0, 3, y], geo[0, 4, y]
            for x in range(scores.shape[3]):
                if sd[x] < conf:
                    continue
                offX, offY = x * 4.0, y * 4.0
                cos, sin = np.cos(ang[x]), np.sin(ang[x])
                h, w = x0[x] + x2[x], x1[x] + x3[x]
                endX = int(offX + cos * x1[x] + sin * x2[x])
                endY = int(offY - sin * x1[x] + cos * x2[x])
                startX, startY = int(endX - w), int(endY - h)
                boxes.append((int(startX * rW), int(startY * rH),
                              int(endX * rW),   int(endY * rH)))
                scores_out.append(float(sd[x]))

        return non_max_suppression(np.array(boxes), probs=scores_out).tolist() if boxes else []

    def detect(self, img, conf=0.5):
        all_b = [self._detect(img, r, conf) for r in self.resolutions]
        flat  = [b for sub in all_b for b in sub]
        return (non_max_suppression(np.array(flat), overlapThresh=0.7).tolist()
                if flat else [])

east = MultiResolutionEAST("frozen_east_text_detection.pb",
                           [(960,960), (1600,1600), (3776,3776)])

# ───────── 2. Tile helpers ─────────
def gen_tiles(img, size, ov):
    h, w = img.shape[:2]
    step = max(size - ov, 1)
    for y in range(0, h, step):
        for x in range(0, w, step):
            yield img[y:y+size, x:x+size], x, y

def detect_symbols(img, size, ov, conf, iou_thr):
    boxes = []
    for tile, ox, oy in gen_tiles(img, size, ov):
        res = symbol_model.predict(tile, device="cuda",
                                   conf=conf, iou=iou_thr,
                                   half=True, verbose=False)
        if res and len(res[0].boxes):
            for b in res[0].boxes:
                x1, y1, x2, y2 = map(int, b.xyxy[0].tolist())
                boxes.append((x1+ox, y1+oy, x2+ox, y2+oy))
    return boxes

# ───────── 3. IoU merge & draw ─────────
def iou(a, b):
    xA, yA = max(a[0], b[0]), max(a[1], b[1])
    xB, yB = min(a[2], b[2]), min(a[3], b[3])
    if xB < xA or yB < yA:
        return 0
    inter = (xB - xA) * (yB - yA)
    return inter / (((a[2]-a[0])*(a[3]-a[1]) +
                     (b[2]-b[0])*(b[3]-b[1]) - inter) + 1e-9)

def merge(boxes, thr=0.3):
    if not boxes:
        return []
    boxes = sorted(boxes, key=lambda b: (b[2]-b[0])*(b[3]-b[1]), reverse=True)
    used = [False]*len(boxes); out=[]
    for i,b in enumerate(boxes):
        if used[i]: continue
        cur = b
        for j in range(i+1, len(boxes)):
            if used[j]: continue
            if iou(cur, boxes[j]) > thr:
                cur = (min(cur[0], boxes[j][0]), min(cur[1], boxes[j][1]),
                       max(cur[2], boxes[j][2]), max(cur[3], boxes[j][3]))
                used[j] = True
        used[i] = True
        out.append(cur)
    return out

def draw(im, boxes, col, th=2):
    im2 = im.copy()
    for (x1,y1,x2,y2) in boxes:
        cv2.rectangle(im2, (x1,y1), (x2,y2), col, th)
    return im2

# ───────── 4. Main batch function ─────────
def main():
    p = argparse.ArgumentParser(
        parents=[cli],
        description="Detect text (EAST) + symbols (YOLO) in a folder."
    )
    p.add_argument("input_dir");  p.add_argument("output_dir")
    p.add_argument("--tile",      type=int,   default=1024)
    p.add_argument("--overlap",   type=int,   default=128)
    p.add_argument("--east_conf", type=float, default=0.5)
    p.add_argument("--yolo_conf", type=float, default=0.25)
    p.add_argument("--merge_iou", type=float, default=0.3)
    args = p.parse_args()

    Path(args.output_dir).mkdir(parents=True, exist_ok=True)
    exts = (".png",".jpg",".jpeg",".bmp",".tif",".tiff")

    for fn in sorted(os.listdir(args.input_dir)):
        if not fn.lower().endswith(exts):
            continue
        img = cv2.cvtColor(np.array(
              Image.open(Path(args.input_dir)/fn).convert("RGB")),
              cv2.COLOR_RGB2BGR)

        print("→", fn)
        t_boxes = east.detect(img, conf=args.east_conf)
        s_raw   = detect_symbols(img, args.tile, args.overlap,
                                 args.yolo_conf, 0.45)
        s_boxes = merge(s_raw, args.merge_iou)
        print(f"   text: {len(t_boxes)}   symbols: {len(s_boxes)}")

        out = draw(img, t_boxes, (0,0,255), 2)
        out = draw(out, s_boxes, (255,0,0), 2)
        cv2.imwrite(str(Path(args.output_dir)/
                        f"{Path(fn).stem}_annotated.png"), out)

    print("✅  Results →", args.output_dir)

if __name__ == "__main__":
    main()





python3 text_symbol_batch.py \
        --east_conf 0.08 --yolo_conf 0.08 \
        "OCR TEST-28-04-25"  OCR_ANNOTATED
